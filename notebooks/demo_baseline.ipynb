{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff717b4",
   "metadata": {},
   "source": [
    "# SocraticFlanT5 - Caption Generation (baseline) | DL2 Project, May 2023\n",
    "---\n",
    "\n",
    "This notebook downloads the images from the validation split of the [MS COCO Dataset (2017 version)](https://cocodataset.org/#download) and the corresponding ground-truth captions and generates captions based on the Socratic model pipeline outlined below. The caption will be generated by the baseline approach:\n",
    "* Baseline: a Socratic model based on the work by [Zeng et al. (2022)](https://socraticmodels.github.io/) where GPT-3 is replaced by [FLAN-T5-xl](https://huggingface.co/docs/transformers/model_doc/flan-t5). \n",
    "\n",
    "In other words, the goal of this jupyter notebook is to reproduce the Socratic Models paper with the Flan-T5 model. This provides a baseline for us to build upon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3c510a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a939ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package loading\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from transformers import set_seed\n",
    "\n",
    "# Local imports\n",
    "from scripts.image_captioning import ClipManager, ImageManager, VocabManager, FlanT5Manager\n",
    "from scripts.image_captioning import LmPromptGenerator as pg\n",
    "from scripts.utils import get_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce9b26c",
   "metadata": {},
   "source": [
    "## Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb879757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the transformers seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd734f5",
   "metadata": {},
   "source": [
    "## Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d35df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to use\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e8dc2e",
   "metadata": {},
   "source": [
    "## Class instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8664150",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_places starting!\n",
      "load_places took 0.0s!\n",
      "load_objects starting!\n",
      "load_objects took 0.6s!\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f94a2a2533574b6f93a308b66f2571d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate the clip manager\n",
    "clip_manager = ClipManager(device)\n",
    "\n",
    "# Instantiate the image manager\n",
    "image_manager = ImageManager()\n",
    "\n",
    "# Instantiate the vocab manager\n",
    "vocab_manager = VocabManager()\n",
    "\n",
    "# Instantiate the Flan T5 manager\n",
    "flan_manager = FlanT5Manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e506806d",
   "metadata": {},
   "source": [
    "## Set image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df9cc91",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "img_paths = {\n",
    "    'Dining room': 'demo_img.png',\n",
    "    'Monkey with gun': 'monkey_with_gun.jpg',\n",
    "    'Cute bear': 'cute_bear.jpg',\n",
    "    'Astronaut with beer': 'astronaut_with_beer.jpg'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db7d7e",
   "metadata": {},
   "source": [
    "## Create text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00ac0d3",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the place features\n",
    "place_emb = clip_manager.get_text_emb([f'Photo of a {p}.' for p in vocab_manager.place_list])\n",
    "\n",
    "# Calculate the object features\n",
    "object_emb = clip_manager.get_text_emb([f'Photo of a {o}.' for o in vocab_manager.object_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30615061",
   "metadata": {},
   "source": [
    "## Load image and compute image embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e536b30c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load image.\n",
    "img_dic = {img_name: image_manager.load_image(img_path) for img_name, img_path in img_paths.items()}\n",
    "# Get image representation\n",
    "img_feat_dic = {img_name: clip_manager.get_img_emb(img) for img_name, img in img_dic.items()}\n",
    "# Show the image\n",
    "for img_name, img in img_dic.items():\n",
    "    print(f'{img_name}:')\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b7a6b4",
   "metadata": {},
   "source": [
    "## Zero shot VLM - Image type classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad9d17",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Zero-shot VLM: classify image type.\n",
    "img_types = ['photo', 'cartoon', 'sketch', 'painting']\n",
    "img_types_emb = clip_manager.get_text_emb([f'This is a {t}.' for t in img_types])\n",
    "\n",
    "# Create a dictionary to store the image types\n",
    "img_type_dic = {}\n",
    "for img_name, img_feat in img_feat_dic.items():\n",
    "    sorted_img_types, img_type_scores = clip_manager.get_nn_text(img_types, img_types_emb, img_feat)\n",
    "    img_type_dic[img_name] = sorted_img_types[0]\n",
    "    print(f'Image type for \"{img_name}\": {img_type_dic[img_name]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a8753a",
   "metadata": {},
   "source": [
    "## Zero shot VLM - Number of people classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69cca22",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Zero-shot VLM: classify number of people.\n",
    "ppl_texts_bool = ['no people', 'people']\n",
    "ppl_emb_bool = clip_manager.get_text_emb([f'There are {p} in this photo.' for p in ppl_texts_bool])\n",
    "\n",
    "ppl_texts_mult = ['is one person', 'are two people', 'are three people', 'are several people', 'are many people']\n",
    "ppl_emb_mult = clip_manager.get_text_emb([f'There {p} in this photo.' for p in ppl_texts_mult])\n",
    "\n",
    "# Create a dictionary to store the number of people\n",
    "num_people_dic = {}\n",
    "\n",
    "for img_name, img_feat in img_feat_dic.items():\n",
    "    sorted_ppl_texts, ppl_scores = clip_manager.get_nn_text(ppl_texts_bool, ppl_emb_bool, img_feat)\n",
    "    ppl_result = sorted_ppl_texts[0]\n",
    "    if ppl_result == 'people':\n",
    "        sorted_ppl_texts, ppl_scores = clip_manager.get_nn_text(ppl_texts_mult, ppl_emb_mult, img_feat)\n",
    "        ppl_result = sorted_ppl_texts[0]\n",
    "    else:\n",
    "        ppl_result = f'are {ppl_result}'\n",
    "\n",
    "    num_people_dic[img_name] = ppl_result\n",
    "    print(f'Number of people in \"{img_name}\": {ppl_result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4108e4",
   "metadata": {},
   "source": [
    "## Zero shot VLM - Image place classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad199da",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Zero-shot VLM: classify places.\n",
    "place_topk = 3\n",
    "\n",
    "# Create a dictionary to store the number of people\n",
    "location_dic = {}\n",
    "for img_name, img_feat in img_feat_dic.items():\n",
    "    sorted_places, places_scores = clip_manager.get_nn_text(vocab_manager.place_list, place_emb, img_feat)\n",
    "    location_dic[img_name] = sorted_places[0]\n",
    "    print(f'Location for {img_name}: {location_dic[img_name]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1dbd03",
   "metadata": {},
   "source": [
    "## Zero shot VLM - Image object classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5968315d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Zero-shot VLM: classify objects.\n",
    "obj_topk = 10\n",
    "\n",
    "# Create a dictionary to store the similarity of each object with the images\n",
    "obj_list_dic = {}\n",
    "for img_name, img_feat in img_feat_dic.items():\n",
    "    sorted_obj_texts, obj_scores = clip_manager.get_nn_text(vocab_manager.object_list, object_emb, img_feat)\n",
    "    object_list = ''\n",
    "    for i in range(obj_topk):\n",
    "        object_list += f'{sorted_obj_texts[i]}, '\n",
    "    object_list = object_list[:-2]\n",
    "    obj_list_dic[img_name] = object_list\n",
    "    print(f'Top 10 objects recognised for \"{img_name}\":\\n{object_list}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0b318d",
   "metadata": {},
   "source": [
    "## Zero shot LM - Caption generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d04be",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Zero-shot LM: generate captions.\n",
    "num_captions = 50\n",
    "\n",
    "# Set LM params\n",
    "model_params = {'temperature': 0.9, 'max_length': 40, 'do_sample': True}\n",
    "\n",
    "# Create dictionaries to store the outputs\n",
    "prompt_dic = {}\n",
    "sorted_caption_map = {}\n",
    "caption_score_map = {}\n",
    "\n",
    "for img_name in img_dic:\n",
    "    # Create the prompt for the language model\n",
    "    prompt_dic[img_name] = pg.create_baseline_lm_prompt(\n",
    "        img_type_dic[img_name], num_people_dic[img_name], location_dic[img_name], obj_list_dic[img_name]\n",
    "    )\n",
    "\n",
    "    # Generate the caption using the language model\n",
    "    caption_texts = flan_manager.generate_response(num_captions * [prompt_dic[img_name]], model_params)\n",
    "\n",
    "    # Zero-shot VLM: rank captions.\n",
    "    caption_emb = clip_manager.get_text_emb(caption_texts)\n",
    "    sorted_captions, caption_scores = clip_manager.get_nn_text(caption_texts, caption_emb, img_feat_dic[img_name])\n",
    "    sorted_caption_map[img_name] = sorted_captions\n",
    "    caption_score_map[img_name] = dict(zip(sorted_captions, caption_scores))\n",
    "    print(f'Best generate caption for \"{img_name}\": \"{sorted_captions[0]}\"\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d2ec8",
   "metadata": {},
   "source": [
    "## Saving the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd6a0ba",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for img_name in img_dic:\n",
    "    generated_caption = sorted_caption_map[img_name][0]\n",
    "    data_list.append({\n",
    "        'image_name': img_name,\n",
    "        'image_path': img_paths[img_name],\n",
    "        'generated_caption': generated_caption,\n",
    "        'cosine_similarity': caption_score_map[img_name][generated_caption]\n",
    "    })\n",
    "pd.DataFrame(data_list).to_csv(f'baseline_outputs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94392a9e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
